# -*- coding: utf-8 -*-
"""ai_sc13x.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PcLMjQKqabiUAMhChMOTZURJKkvZsr17

<img src='https://i.imgur.com/RDAD11M.png' width = '200' align = 'right'>

# SC13x 

## Linear Algebra

## 1. $\vec{c} \cdot \vec{d}$ 를 구해보세요. 이 두 개의 vector는 orthogonal 관계 (직교)에 있나요? 왜 그런가요? 왜 아닌가요?

\begin{align}
\vec{c} = \begin{bmatrix}3 & 7 & -2 & 12\end{bmatrix}
\qquad
\vec{d} = \begin{bmatrix}9 & -7 & 4 & 6\end{bmatrix}
\end{align}
"""

import numpy as np

c = [3,7,-2,12]
d = [9,-7,4,6]

print('벡터 C와 D의 내적 : ', np.dot(c,d)) # 내적이 0일 때 직교, 내적식의 코사인값이 0이기 때문

"""## 2. $E^{-1}$ 와 $E^{T}$ 를 구하세요.

\begin{align}
E = 
\begin{bmatrix}
    7 & 4 & 2 \\
    1 & 3 & -1 \\
    2 & 6 & -4
\end{bmatrix}
\end{align}
"""

E = np.array([[7,4,2],[1,3,-1],[2,6,-4]])
E_trans = E.T
E_inv = np.linalg.inv(E)
print('전치행렬 : \n', E_trans)
print('\n역행렬 : \n', E_inv)
print('\n역행렬 첫 행의 요소합 : ', np.round(E_inv[0,:].sum(),2))
print('\n전치행렬 첫 행의 요소합 : ', np.round(E_trans[0,:].sum(),2))

"""## 3. $|F|$ 를 구하세요. 이 행렬은 어떤 의미가 있나요?

\begin{align}
F = 
\begin{bmatrix}
    2 & -2 & 5 \\
    4 & 1 & 10 \\
    12 & 6 & 30
\end{bmatrix}
\end{align}
"""

F = np.array([[2,-2,5],[4,1,10],[12,6,30]])
print('행렬 F의 Deterinant : ', np.linalg.det(F))

"""## 4. 다음 데이터의 covariance, correlation을 구하세요.

- $x = [820, 760, 1250, 990, 1080, 1450, 1600]$

- $y = [0, 1, 7, 1, 0, 6, 4]$
"""

import pandas as pd

df = pd.DataFrame({'x':[820,760,1250,990,1080,1450,1600],'y':[0,1,7,1,0,6,4]})
print('공분산 :\n', df.cov())
print('\n상관계수 :\n',df.corr())

"""## 5. 다음 데이터를 표준화 하세요.

아래 링크를 참조하세요.

<https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html>
"""

import pandas as pd

data = {"Country": ["England","Wales","Scotland","North Ireland"], 
        "Cheese": [105,103,103,66], 
        "Carcass_Meat": [245,227,242,267], 
        "Other_Meat": [685, 803, 750, 586], 
        "Fish": [147, 160, 122, 93], 
        "Fats_and_Oils": [193, 235, 184, 209], 
        "Sugars": [156, 175, 147, 139], 
        "Fresh_Potatoes": [720, 874, 566, 1033], 
        "Fresh_Veg": [253, 265, 171, 143], 
        "Other_Veg": [488, 570, 418, 355], 
        "Processed_Potatoes": [198, 203, 220, 187], 
        "Processed_Veg": [360, 365, 337, 334], 
        "Fresh_Fruit": [1102, 1137, 957, 674], 
        "Cereals": [1472, 1582, 1462, 1494], 
        "Beverages": [57,73,53,47], 
        "Soft_Drinks": [1374, 1256, 1572, 1506], 
        "Alcoholic Drinks": [375, 475, 458, 135], 
        "Confectionery": [54, 64, 62, 41]}

df = pd.DataFrame(data)

df

import matplotlib.pyplot as plt
import sklearn
from sklearn.preprocessing import StandardScaler

ft = df.iloc[:,1:]
scaler = StandardScaler()
ft_scaled = scaler.fit_transform(ft)
np.round(ft_scaled[0,5],2)

"""## 6. 위 데이터에 PCA 를 적용 후 scatterplot을 그리세요."""

from sklearn.decomposition import PCA
print('피쳐 테이블 : ', ft.shape, '\n', np.array(ft))
pca = PCA()
pca.fit(ft_scaled)
df_p = pca.transform(ft_scaled)
print('\nPCA결과 : ', df_p.shape, '\n', df_p)
print('\nPC2의 0번째 index 값 : ', np.round(df_p[0,1],2))

pc1 = df_p[:,0]
pc2 = df_p[:,1]

plt.scatter(pc1,pc2)

"""## 7. 아래 데이터에 대해 k-means clustering을 적용 후, 결과를 그래프로 그리세요.
- cluster의 개수는 4개로 지정합니다. 
"""

points = pd.read_csv('https://ds-lecture-data.s3.ap-northeast-2.amazonaws.com/sc13x/data.csv')
points.head()

print('Shape : ', points.shape, '\n')
plt.scatter(points.x,points.y)

from sklearn.cluster import KMeans
import seaborn as sns

scaler = StandardScaler()
p_s = scaler.fit_transform(points)

sse = {}

for k in range(1,10):
  kmeans = KMeans(n_clusters=k, random_state=1)
  kmeans.fit(p_s)
  sse[k] = kmeans.inertia_

plt.title('The Elbow Method')
plt.xlabel('Values of k')
plt.ylabel('SSE')
sns.pointplot(x=list(sse.keys()), y=list(sse.values()))
plt.show()

# 최종 모델 학습
kmeans = KMeans(n_clusters=4, max_iter=50, random_state=42)
kmeans.fit(p_s)

# 고객별 클러스터 지정
cluster_labels = kmeans.labels_

points = points.assign(Cluster = cluster_labels)
points

print('가장 개수가 많은 클러스터의 데이터 개수 : ', points['Cluster'].value_counts().max(), '\n')
fig = plt.figure(figsize = (13,10))
ax = fig.add_subplot(111, projection='3d')
ax.scatter(xs = points.x, ys = points.y, c=points.Cluster)
plt.show()

"""# SC 3점 요구사항:
위에서 요구된 사항들을 모두 정확하게 만족하였으며, 아직 시간이 남았다면 아래 2개의 추가 조건들 중 하나를 만족하는 경우 3점을 얻을 수 있습니다.

아래 요구사항들은 모두 **optional** 임을 다시 한 번 강조합니다. (필수 요구사항이 아닙니다.)

- 6번의 PCA 결과에 대해서 `Scree plot`을 추가하세요.

- 7번에서 k값을 선택하는 과정을 논리적으로 설명하세요.

"""

